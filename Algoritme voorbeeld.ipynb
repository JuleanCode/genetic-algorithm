{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>12.47</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2.63</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>11.81</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.74</td>\n",
       "      <td>21.5</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.26</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>12.29</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.74</td>\n",
       "      <td>428.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.10</td>\n",
       "      <td>18.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.77</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>12.29</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.21</td>\n",
       "      <td>18.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.83</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0     14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1     13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2     13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3     14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4     13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..      ...         ...   ...                ...        ...            ...   \n",
       "95    12.47        1.52  2.20               19.0      162.0           2.50   \n",
       "96    11.81        2.12  2.74               21.5      134.0           1.60   \n",
       "97    12.29        1.41  1.98               16.0       85.0           2.55   \n",
       "98    12.37        1.07  2.10               18.5       88.0           3.52   \n",
       "99    12.29        3.17  2.21               18.0       88.0           2.85   \n",
       "\n",
       "    flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0         3.06                  0.28             2.29             5.64  1.04   \n",
       "1         2.76                  0.26             1.28             4.38  1.05   \n",
       "2         3.24                  0.30             2.81             5.68  1.03   \n",
       "3         3.49                  0.24             2.18             7.80  0.86   \n",
       "4         2.69                  0.39             1.82             4.32  1.04   \n",
       "..         ...                   ...              ...              ...   ...   \n",
       "95        2.27                  0.32             3.28             2.60  1.16   \n",
       "96        0.99                  0.14             1.56             2.50  0.95   \n",
       "97        2.50                  0.29             1.77             2.90  1.23   \n",
       "98        3.75                  0.24             1.95             4.50  1.04   \n",
       "99        2.99                  0.45             2.81             2.30  1.42   \n",
       "\n",
       "    od280/od315_of_diluted_wines  proline  target  \n",
       "0                           3.92   1065.0       0  \n",
       "1                           3.40   1050.0       0  \n",
       "2                           3.17   1185.0       0  \n",
       "3                           3.45   1480.0       0  \n",
       "4                           2.93    735.0       0  \n",
       "..                           ...      ...     ...  \n",
       "95                          2.63    937.0       1  \n",
       "96                          2.26    625.0       1  \n",
       "97                          2.74    428.0       1  \n",
       "98                          2.77    660.0       1  \n",
       "99                          2.83    406.0       1  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "data = load_wine()\n",
    "\n",
    "#De dataset van sklearn wordt omgezet naar pandas.\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "#De doelvariabele voor het NN wordt appart genomen.\n",
    "df['target'] = data.target\n",
    "multicolumns = df.loc[:, df.columns != 'target']\n",
    "\n",
    "#Voordat we verder gaan met een neural netwerk kijken we naar de waardes van de dataset. We roepen de eerste 100 regels aan.\n",
    "#Zoals te zien heeft de target een discrete waarde, hierdoor wordt er gebruikt gemaakt van MLPClassifier.\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score NN1:  0.9722222222222222\n",
      "score NN2:  0.4722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y = df['target']\n",
    "X = multicolumns\n",
    "\n",
    "#Het aanmaken van Nural Netwerken.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "NN1 = MLPClassifier(activation = 'logistic', hidden_layer_sizes = 100, random_state = 1, max_iter = 500).fit(X_train, y_train)\n",
    "#.score geeft de gemiddelde accuracy score weer.\n",
    "scoreNN1 = NN1.score(X_test, y_test)\n",
    "print('score NN1: ',scoreNN1)\n",
    "\n",
    "NN2 = MLPClassifier(activation = 'relu', hidden_layer_sizes = 50, random_state = 1, max_iter = 500).fit(X_train, y_train)\n",
    "\n",
    "scoreNN2 = NN2.score(X_test, y_test) \n",
    "print('score NN2: ',scoreNN2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def NN(function,layers,learning):\n",
    "    return MLPClassifier(activation = function, hidden_layer_sizes = layers, learning_rate = learning, random_state = 1, max_iter = 500).fit(X_train, y_train)\n",
    "\n",
    "def fitness(function,layers,learning):\n",
    "    network = NN(function,layers,learning)\n",
    "\n",
    "    accuracy = network.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    child1 = np.append(parent1[1:2], parent2[2:])\n",
    "    child2 = np.append(parent2[1:2], parent1[2:])\n",
    "    return child1, child2\n",
    "\n",
    "def mutation(function,layers,learning):\n",
    "    gens = [function,layers,learning]\n",
    "    gen = random.choice(gens)\n",
    "    while gen == function:\n",
    "        function = random.choice(functions)\n",
    "    \n",
    "    while gen == layers:\n",
    "        layers = random.randrange(1,100)\n",
    "\n",
    "    while gen == learning:\n",
    "        learning = random.choice(learning_rates)\n",
    "        \n",
    "    print(\"The new features are: ['\", function,\"' '\",layers,\"' '\",learning,\"']\")\n",
    "    accuracy = fitness(function,layers,learning)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "number = 5\n",
    "\n",
    "total = []\n",
    "\n",
    "for i in range(number):\n",
    "    score = True\n",
    "\n",
    "    while score == True:\n",
    "        network = []\n",
    "        functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "        function = random.choice(functions)\n",
    "\n",
    "        layers = random.randrange(1,100)\n",
    "\n",
    "        learning_rates = ['constant','invscaling','adaptive']\n",
    "        learning = random.choice(learning_rates)\n",
    "\n",
    "        accuracyNN = fitness(function,layers,learning)\n",
    "\n",
    "        # print(accuracyNN)\n",
    "\n",
    "        if accuracyNN != 1.0: #We don't want the parent to be optimal yet!\n",
    "            network.append(accuracyNN)\n",
    "            network.append(function)\n",
    "            network.append(layers)\n",
    "            network.append(learning)\n",
    "\n",
    "            total.append(network)\n",
    "            score = False\n",
    "\n",
    "total.sort(reverse=True)\n",
    "\n",
    "# print(total)\n",
    "\n",
    "print('There are',number,'parants, there accuracys scores are: \\n')\n",
    "\n",
    "for j in range(0,number):\n",
    "    print(total[j][0])\n",
    "\n",
    "print('Out of the two best parents we wil make a few childs!')\n",
    "\n",
    "#Creating childs    \n",
    "features_childs = crossover(total[0],total[1])\n",
    "\n",
    "i = 1\n",
    "for child in features_childs:\n",
    "    print('\\nfeatures child',i,': ',child)\n",
    "    accuracy = fitness(str(child[0]),int(child[1]),str(child[2]))\n",
    "    print('The accuracy score with this features: ',accuracy)\n",
    "    print('The features of the parents were:', total[0][1:4],'and',total[1][1:4])\n",
    "    print('The accuracy score of the parents were: ',total[0][0],' and ', total[1][0])\n",
    "\n",
    "    if accuracy == 1.0:\n",
    "        print('This child with the features',child,'performs optimatly!','\\n')\n",
    "    elif accuracy > total[0][0]:\n",
    "        print('The accuracy score of the child is better than that from both parents! But still not optimal..','\\n')\n",
    "    elif accuracy == total[0][0]:\n",
    "        print('The accuracy score of the child is equal to the accuracy score from at least one parent, the best parent for sure!','\\n')\n",
    "    else:\n",
    "        print('The accuracy score of child',i,\" isn't higher than or, equal to, the accuracy score of the best parent, so it gets mutated!\",'\\n')\n",
    "        new_accuracy = mutation(str(child[0]),int(child[1]),str(child[2]))\n",
    "        if new_accuracy == 1.0:\n",
    "            print('This child with the features performs optimatly! The accuracy score is ',new_accuracy,'\\n')\n",
    "        elif new_accuracy > total[0][0]:\n",
    "            print('The new accuracy score of the child is ',new_accuracy,', this accuracy score is better than the accuracy score from both parents! But still not optimal..','\\n')\n",
    "        elif new_accuracy == total[0][0]:\n",
    "            print('The new accuracy score of the child is ',new_accuracy,', this accuracy score is equal to the accuracy score from at least one parent, the best parent for sure!','\\n')\n",
    "        else:\n",
    "            print('The new accuracy score of the child is ',new_accuracy,', unfortunatly, this accuracy score is still not better than the accuracy score from both parents or at least the best parent..','\\n')\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 parants, there accuracys scores are: \n",
      "\n",
      "0.7222222222222222\n",
      "0.6111111111111112\n",
      "0.5555555555555556\n",
      "0.3888888888888889\n",
      "0.3888888888888889\n",
      "First we will make a child out of the two best parents!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#GOEDE CODE MET # FEATURES!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def NN(function,layers,learning):\n",
    "    return MLPClassifier(activation = function, hidden_layer_sizes = layers, learning_rate = learning, random_state = 1, max_iter = 500).fit(X_train, y_train)\n",
    "\n",
    "def fitness(function,layers,learning):\n",
    "    network = NN(function,layers,learning)\n",
    "\n",
    "    accuracy = network.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    child1 = np.append(parent1[1:2], parent2[2:])\n",
    "    child2 = np.append(parent2[1:2], parent1[2:])\n",
    "    return child1, child2\n",
    "\n",
    "def mutation(function,layers,learning):\n",
    "    gens = [function,layers,learning]\n",
    "    gen = random.choice(gens)\n",
    "    while gen == function:\n",
    "        function = random.choice(functions)\n",
    "    \n",
    "    while gen == layers:\n",
    "        layers = random.randrange(1,100)\n",
    "\n",
    "    while gen == learning:\n",
    "        learning = random.choice(learning_rates)\n",
    "        \n",
    "    print(\"The new features are: ['\", function,\"' '\",layers,\"' '\",learning,\"']\")\n",
    "    accuracy = fitness(function,layers,learning)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "number = 5\n",
    "\n",
    "total = []\n",
    "\n",
    "for i in range(number):\n",
    "    score = True\n",
    "\n",
    "    while score == True:\n",
    "        network = []\n",
    "        functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "        function = random.choice(functions)\n",
    "\n",
    "        layers = random.randrange(1,100)\n",
    "\n",
    "        learning_rates = ['constant','invscaling','adaptive']\n",
    "        learning = random.choice(learning_rates)\n",
    "\n",
    "        accuracyNN = fitness(function,layers,learning)\n",
    "\n",
    "        # print(accuracyNN)\n",
    "\n",
    "        if accuracyNN != 1.0: #We don't want the parent to be optimal yet!\n",
    "            network.append(accuracyNN)\n",
    "            network.append(function)\n",
    "            network.append(layers)\n",
    "            network.append(learning)\n",
    "\n",
    "            total.append(network)\n",
    "            score = False\n",
    "\n",
    "total.sort(reverse=True)\n",
    "\n",
    "# print(total)\n",
    "\n",
    "print('There are',number,'parants, there accuracys scores are: \\n')\n",
    "\n",
    "for j in range(0,number):\n",
    "    print(total[j][0])\n",
    "\n",
    "print('First we will make a child out of the two best parents!')\n",
    "\n",
    "#Creating childs \n",
    "j = 1\n",
    "loop=True\n",
    "while loop == True:\n",
    "    if j <= 4:\n",
    "        features_childs = crossover(total[0],total[j])\n",
    "\n",
    "        i = 1\n",
    "        for child in features_childs:\n",
    "            print('\\nfeatures child',i,': ',child)\n",
    "            accuracy = fitness(str(child[0]),int(child[1]),str(child[2]))\n",
    "            print('The accuracy score with this features: ',accuracy)\n",
    "            print('The features of the parents were:', total[0][1:4],'and',total[1][1:4])\n",
    "            print('The accuracy score of the parents were: ',total[0][0],' and ', total[1][0])\n",
    "\n",
    "            if accuracy == 1.0:\n",
    "                print('This child with the features',child,'performs optimatly!','\\n')\n",
    "                loop = False\n",
    "                break\n",
    "            elif accuracy > total[0][0]:\n",
    "                print('The accuracy score of the child is better than that from both parents! But still not optimal..','\\n')\n",
    "            elif accuracy == total[0][0]:\n",
    "                print('The accuracy score of the child is equal to the accuracy score from at least one parent, the best parent for sure!','\\n')\n",
    "            else:\n",
    "                print('The accuracy score of child',i,\" isn't higher than or, equal to, the accuracy score of the best parent, so it gets mutated!\",'\\n')\n",
    "                new_accuracy = mutation(str(child[0]),int(child[1]),str(child[2]))\n",
    "                if new_accuracy == 1.0:\n",
    "                    print('This child with the features performs optimatly! The accuracy score is ',new_accuracy,'\\n')\n",
    "                    loop = False\n",
    "                    break\n",
    "                elif new_accuracy > total[0][0]:\n",
    "                    print('The new accuracy score of the child is ',new_accuracy,', this accuracy score is better than the accuracy score from both parents! But still not optimal..','\\n')\n",
    "                elif new_accuracy == total[0][0]:\n",
    "                    print('The new accuracy score of the child is ',new_accuracy,', this accuracy score is equal to the accuracy score from at least one parent, the best parent for sure!','\\n')\n",
    "                else:\n",
    "                    print('The new accuracy score of the child is ',new_accuracy,', unfortunatly, this accuracy score is still not better than the accuracy score from both parents or at least the best parent..','\\n')\n",
    "            i += 1\n",
    "        parent = j + 1\n",
    "        print('\\nWith a crossover (and possibly mutations) between the 1 and the',parent,\"the childs weren't optimal, we wil look at the next parent!\")\n",
    "        j += 1\n",
    "    else:\n",
    "        print('\\nAll parents have done crossover to create, and some childs also had a mutation, but unfortunatlly is there no optimal child found..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 parants, there accuracys scores are: \n",
      "\n",
      "0.9722222222222222\n",
      "0.9722222222222222\n",
      "0.8055555555555556\n",
      "0.4722222222222222\n",
      "0.3888888888888889\n",
      "Out of the two best parents we wil make two childs!\n",
      "\n",
      "features child 1 :  ['tanh' '31']\n",
      "The accuracy score with this features:  0.9722222222222222\n",
      "The accuracy score of the parents were:  0.9722222222222222  and  0.9722222222222222\n",
      "The accuracy score of the child is equal to the accuracy score from at least one parent, the best parent for sure! \n",
      "\n",
      "\n",
      "features child 2 :  ['logistic' '27']\n",
      "The accuracy score with this features:  0.9722222222222222\n",
      "The accuracy score of the parents were:  0.9722222222222222  and  0.9722222222222222\n",
      "The accuracy score of the child is equal to the accuracy score from at least one parent, the best parent for sure! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#DE GOEDE CODE!!\n",
    "# \n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def NN(function,layers):\n",
    "    return MLPClassifier(activation = function, hidden_layer_sizes = layers, random_state = 1, max_iter = 500).fit(X_train, y_train)\n",
    "\n",
    "def fitness(function,layers):\n",
    "    network = NN(function,layers)\n",
    "\n",
    "    accuracy = network.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    child1 = np.append(parent1[0], parent2[1])\n",
    "    child2 = np.append(parent2[0], parent1[1])\n",
    "    return child1, child2\n",
    "\n",
    "def mutation(function,layers):\n",
    "    gens = [function,layers]\n",
    "    gen = random.choice(gens)\n",
    "    while gen == function:\n",
    "        function = random.choice(functions)\n",
    "    \n",
    "    while gen == layers:\n",
    "        layers = random.randrange(1,100)\n",
    "    print(\"The new features are: ['\", function,\"' '\",layers,\"']\")\n",
    "    accuracy = fitness(function,layers)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "number = 5\n",
    "\n",
    "total = []\n",
    "\n",
    "for i in range(number):\n",
    "    score = True\n",
    "\n",
    "    while score == True:\n",
    "        network = []\n",
    "        functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "        function = random.choice(functions)\n",
    "\n",
    "        layers = random.randrange(1,100)\n",
    "\n",
    "        accuracyNN = fitness(function,layers)\n",
    "\n",
    "        # print(accuracyNN)\n",
    "\n",
    "        if accuracyNN != 1.0: #We don't want the parent to be optimal yet!\n",
    "            network.append(accuracyNN)\n",
    "            network.append(function)\n",
    "            network.append(layers)\n",
    "\n",
    "            total.append(network)\n",
    "            score = False\n",
    "\n",
    "total.sort(reverse=True)\n",
    "\n",
    "# print(total)\n",
    "\n",
    "print('There are',number,'parants, there accuracys scores are: \\n')\n",
    "\n",
    "for j in range(0,number):\n",
    "    print(total[j][0])\n",
    "\n",
    "print('Out of the two best parents we wil make two childs!')\n",
    "\n",
    "#Creating childs    \n",
    "features_parent1 = np.append(total[0][1], total[0][2])\n",
    "features_parent2 = np.append(total[1][1], total[1][2])\n",
    "\n",
    "features_childs = crossover(features_parent1,features_parent2)\n",
    "\n",
    "i = 1\n",
    "for child in features_childs:\n",
    "    print('\\nfeatures child',i,': ',child)\n",
    "    accuracy = fitness(str(child[0]),int(child[1]))\n",
    "    print('The accuracy score with this features: ',accuracy)\n",
    "    print('The accuracy score of the parents were: ',total[0][0],' and ', total[1][0])\n",
    "\n",
    "    if accuracy == 1.0:\n",
    "        print('This child with the features',child,'performs optimatly!','\\n')\n",
    "    elif accuracy > total[0][0]:\n",
    "        print('The accuracy score of the child is better than that from both parents! But still not optimal..','\\n')\n",
    "    elif accuracy == total[0][0]:\n",
    "        print('The accuracy score of the child is equal to the accuracy score from at least one parent, the best parent for sure!','\\n')\n",
    "    else:\n",
    "        print('The accuracy score of child',i,\" isn't higher than or, equal to, the accuracy score of the best parent, so it gets mutated!\",'\\n')\n",
    "        new_accuracy = mutation(str(child[0]),int(child[1]))\n",
    "        if new_accuracy == 1.0:\n",
    "            print('This child with the features performs optimatly! The accuracy score is ',new_accuracy,'\\n')\n",
    "        elif new_accuracy > total[0][0]:\n",
    "            print('The new accuracy score of the child is ',new_accuracy,', this accuracy score is better than the accuracy score from both parents! But still not optimal..','\\n')\n",
    "        elif new_accuracy == total[0][0]:\n",
    "            print('The new accuracy score of the child is ',new_accuracy,', this accuracy score is equal to the accuracy score from at least one parent, the best parent for sure!','\\n')\n",
    "        else:\n",
    "            print('The new accuracy score of the child is ',new_accuracy,', unfortunatly, this accuracy score is still not better than the accuracy score from both parents or the best parent..','\\n')\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 parants, there accuracy: \n",
      "\n",
      "0.9722222222222222\n",
      "0.9722222222222222\n",
      "0.9444444444444444\n",
      "0.3888888888888889\n",
      "0.2222222222222222\n",
      "Out of the two best parents we wil make two childs!\n",
      "\n",
      "features child 1 :  ['tanh' '38' 'constant']\n",
      "The accuracy with this features:  0.9722222222222222\n",
      "The accuracy of the parents were:  0.9722222222222222  and  0.9722222222222222\n",
      "The accuracy of the child is better!\n",
      "\n",
      "features child 2 :  ['tanh' '73' 'invscaling']\n",
      "The accuracy with this features:  0.9722222222222222\n",
      "The accuracy of the parents were:  0.9722222222222222  and  0.9722222222222222\n",
      "The accuracy of the child is better!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def NN(function,layers,learning):\n",
    "    return MLPClassifier(activation = function, hidden_layer_sizes = layers, learning_rate = learning, random_state = 1, max_iter = 500).fit(X_train, y_train)\n",
    "\n",
    "def fitness(function,layers,learning):\n",
    "    network = NN(function,layers,learning)\n",
    "\n",
    "    accuracy = network.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "number = 5\n",
    "\n",
    "total = []\n",
    "\n",
    "for i in range(number):\n",
    "    network = []\n",
    "    functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "    function = random.choice(functions)\n",
    "\n",
    "    layers = random.randrange(1,100)\n",
    "\n",
    "    learning_rates = ['constant','invscaling','adaptive']\n",
    "    learning = random.choice(learning_rates)\n",
    "\n",
    "    accuracyNN = fitness(function,layers,learning)\n",
    "    \n",
    "    network.append(accuracyNN)\n",
    "    network.append(function)\n",
    "    network.append(layers)\n",
    "    network.append(learning)\n",
    "\n",
    "    total.append(network)\n",
    "\n",
    "total.sort(reverse=True)\n",
    "\n",
    "# print(total)\n",
    "\n",
    "print('There are',number,'parants, there accuracy: \\n')\n",
    "\n",
    "for j in range(0,number):\n",
    "    print(total[j][0])\n",
    "\n",
    "print('Out of the two best parents we wil make two childs!')\n",
    "\n",
    "# for rate in total[0][3]:\n",
    "#     a = rate\n",
    "\n",
    "# for rate2 in total[1][3]:\n",
    "#     b = rate2\n",
    "\n",
    "# print('sRg ',total[0][1])\n",
    "# print('zdh ',total[0][2])\n",
    "# print('dthy ',total[0][3])\n",
    "\n",
    "# test = total\n",
    "# # print(test)\n",
    "\n",
    "# test[0].pop(0)\n",
    "# test[1].pop(0)\n",
    "\n",
    "# print(test)\n",
    "# print(total)\n",
    "\n",
    "\n",
    "# features_parent1 = test[0]\n",
    "# features_parent2 = test[1]\n",
    "\n",
    "# print(features_parent1)\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    child1 = np.append(parent1[1:2], parent2[2:])\n",
    "    child2 = np.append(parent2[1:2], parent1[2:])\n",
    "    return child1, child2\n",
    "\n",
    "features_childs = crossover(total[0],total[1])\n",
    "\n",
    "i = 1\n",
    "for child in features_childs:\n",
    "    print('\\nfeatures child',i,': ',child)\n",
    "    accuracy = fitness(str(child[0]),int(child[1]),str(child[2]))\n",
    "    print('The accuracy with this features: ',accuracy)\n",
    "    print('The accuracy of the parents were: ',total[0][0],' and ', total[1][0])\n",
    "    if accuracy >= total[0][0]:\n",
    "        print('The accuracy of the child is better!')\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4534337cfa3b6d363df04911c1149f2d359ec96a51e9b5c4488fbc7c2008cfb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
